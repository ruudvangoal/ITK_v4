\documentclass{article}
\newcommand{\Section}[1]{\vspace{-8pt}\section{\hskip-1em.~~#1}\vspace{-3pt}}
\newcommand{\SubSection}[1]{\vspace{-3pt}\subsection{\hskip -1em.~~#1}\vspace{-3pt}}
\newcommand{\X}{{\bf X}}
\newcommand{\x}{{\bf x}}
\newcommand{\Y}{{\bf Y}}
\newcommand{\y}{{\bf y}}
\newcommand{\Z}{{\bf Z}}
\newcommand{\z}{{\bf z}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\I}{{\bs I}}
\newcommand{\J}{{\bs J}}
\newcommand{\R}{{\bs R}}
\newcommand{\Id}{{\text{\bf Id}}}
\newcommand{\bSigma}{\boldsymbol \Sigma}
\usepackage{amsmath,amssymb,algorithm,algorithmic}
\usepackage{times}
\usepackage{setspace,verbatim}
\usepackage{epsfig,url}

\begin{document}
\vspace{-0.1in}
\title{An introduction to ITK version 4 registration}
\author{Anonymous}
\maketitle              
\begin{abstract}
The ITKv4 registration framework is a unified system for performing
multi-threaded affine and deformable image registration.  The revised
framework supports composite transformations, unbiased registration,
the simultaneous use of multiple similarity metrics,
multi-channel/tensor image registration and geometrically correct
transformation of covariant vectors and tensors via the composite
transform framework and transformations based on finite element
models.  ITKv4 also contains new metrics that can be used for
registering point sets, curves and surfaces as well as a set of
efficiently implemented neighborhood correlation metrics.  Despite
these significant additions, the user interface to the framework is,
at the basic level, unchanged from prior versions of ITK.
Furthermore, we provide new optimization strategies that simplify the
user experience by reducing the number of parameters that need to be
set by the user.
\end{abstract}

\section{Introduction}
{\bf What is the current state of image registration?}  As image
registration methods mature---and their capabilities become more
widely recognized---the number of applications increase.
Consequently, image registration has largely transitioned, over the
last 10 years, from being a field of active research, and few applied
results, to one where the main focus is translational.  Image
registration is now used to derive quantitative biomarkers from
images, plays a major role in some clinical products (especially in
radiation oncology), has led to numerous new findings in studies of
brain and behavior and is a critical component in applications in
pathology, microscopy, surgical planning and more.

% {\bf How is image registration applied?}

{\bf What role has ITK filled in the registration world?}  The Insight
ToolKit is a standard-bearer for medical image processing algorithms
and, in particular, for image registration methods.  Image
registration was cited as the number X most important contribution of
ITK (cite Jesus's work).  Numerous papers use ITK algorithms as
standard references for implementations of Demons registration and mutual
information-based rigid registration.  Multiple toolkits extend ITK
registration methods in exciting ways:  Elastix, Slicer, ANTs (name
more).  Thus, the impact of having only a few well-implemented
methods, in the 3.x version of ITK, is significant.  
%  What papers use ITK as a standard for comparison?  What other software builds on ITK registration?


%How does the v4 registration framework build on the past?  What does it contribute that's new?  
% What is it? Why were these the tools we chose to contribute?  
{\bf ITKv4 Registration: What it is.}
The original goals of the version 4 registration framework refactoring
were to both simplify and extend the techniques available in version
3.x.  We aimed to unify the dense (PDE, FEM) registration framework
with the low-dimensional (B-Spline, Affine, rigid) framework by
introducing composite transforms, deformation field transforms and
specializations that allowed these to be optimized efficiently.  We
intended to add robust metrics to the toolkit.  We aimed to simplify
parameter setting by adding helper methods that use well-known
principles of image registration to automatically scale transform
components and set optimization parameters.  We also sought to apply
ITK transforms to objects such as variable length vectors, covariant
vectors and tensors while taking into account orientation if
necessary.  Finally, our goal was to reconfigure the whole framework
to use multi-threading in as many locations as possible and ultimately
compare the multi-core approach to GPU-specific implementations.
These goals have largely been achieved.  

% Our experience with developing ITK 3.x, ANTs, DTI-TK and numerous Insight Journal articles provided a clear 

% What isn't it? Why did we not focus, for instance, on optimal speed
% implementations?
{\bf ITKv4 Registration: What it's not.} Although the current
framework exploits multi-core architectures, we did not focus on
optimal speed implementations (except on the GPU).  We did not
implement parameterized surface-based registration methods, although
the point-set metric framework can be used to achieve something of the
sort.  Integration with the FEM framework is currently minimal.
Additional validation is necessary.  The ability to stream large
datasets to the registration framework is not tested and has not
entered, at a deep level, into design considerations.  These issues
can all be overcome by external toolkits without fundamental changes
to the existing code base.

% graceful failure of an algorithm.  Should not be catastrophic. A nice feedback loop for software.  

%{\bf procedure: 1. clinicians are conservative.  2.  first, prove robustness.  3. provide useful and encouraging feedback.  4. fail gracefully when do fail.   }

% good average performance versus good performance on a given dataset.

The remainder of the document will provide an overview of the new
framework.  We first establish nomenclature.  We then summarize the
new framework's capabilities.  The next section will highlight
functionality through a series of examples.  We then establish
performance benchmarks for ITKv4 release XXX.  Finally, we discuss the
future of the framework.

\section{Nomenclature}
We will use the nomenclature below to designate an image registration
algorithm pictorially.  This nomenclature is intended to be a
descriptive, but also technically correct, system for visually
representing algorithms and applications of registration.  Ideally,
any standard algorithm can be written in the nomenclature below.
\begin{description}
\item [A position:] ${\bf x} \in \Omega$ where $\Omega$ is the domain. 
\item [An image:]  $ I \colon \Omega^d \to \mathbb{R}^n$ where $n$ is the
  number of components per pixel and $d$ is dimensionality.
\item [Domain map:] $ \phi \colon \Omega  \to \Omega $ where $\to$ may be
  replaced with any mapping symbol below. 
\item [Affine mapping:] $\rightarrow$ a low-dimensional
  transformation: affine, rigid, translation, etc. 
\item [Deformation field:] $ \rightsquigarrow$ deformation field mapping $J$
  to $I$.
\item [Spline-based mapping:] $\rightsquigarrow_b$ e.g. B-Spline field mapping $J$
  to $I$.
\item [Diffeomorphic mapping:] $ \leftrightsquigarrow$ these maps
  should have an accurate inverse that is computed in the algorithm or can be computed from the results.
\item [Composite mapping:] $\phi=\phi_1(\phi_2({\bf x}))$ is defined by $\leftrightsquigarrow
  \rightarrow$ where $\phi_2$ is of type $\leftrightsquigarrow$ which precedes the application of $\rightarrow$.
\item[Not invertible:]  $\nleftrightarrow$ indicates a mapping that is
  not guaranteed invertible.
% \item [Transport versus diffeomorphism] intrasubject versus intersubject.
% \item [Resolution effects]  ...
% \item [accuracy vs precision] obsessed with accuracy because we dont
% know the precision we need
% \item [Evaluation data] is there any?
% \item [Serial vs longitudinal]  short time scale versus long time scale
% \item [Pathology] appearance changes ...
% \item [whole body atlas] map any image to whole body
% \item [radiation oncology] techs understand translation versus rotation versus deformation.
\end{description}
A standard Demons registration application that maps a labeling from
one image, $I$, into another, $J$, would then be written:
$$
J \rightsquigarrow \rightarrow  I .
$$
The notation means that the algorithm first computes an affine mapping
from $I$ to $J$ and then computes a deformation from $I( \rightarrow )$
to $J$.  Note, also, that the tail of the mapping indicates the
transform's domain.  The head of the arrow indicates its range.  This
is an important distinction for deformable maps. 

\section{Overview of the unified framework}

\subsection{Simplified registration example}

\subsection{Transform changes}
\subsubsection{Deformation field transforms}
\subsubsection{Composite transforms}
Composite transform I/O

\subsection{Optimizer changes}
\subsubsection{Composite transform optimization}

\subsection{Metric changes}
The model used for multi-threading. 
\subsubsection{Correlation metrics}
\subsubsection{Pointset metrics}
I/O and data representation
\subsubsection{Revised mutual information metric}
\subsubsection{Multivariate metric}
\subsubsection{Multi-channel metric}

\subsection{The virtual domain}
\subsubsection{Application in multi-resolution optimization}
\subsubsection{Unbiased registration}

\section{ITKv4 registration by example}

\subsection{Composite registration}
\subsection{Demons registration}
\subsection{BSpline registration}
\subsection{Multi-channel registration}
\subsection{Tensor registration}
\subsection{Diffeomorphic registration}
\subsection{Diffeomorphic registration with two metrics}
\subsection{GPU Demons}

\section{ITKv4 registration benchmarks}

Comparison with ANTs and Flirt.  

Speed comparison for multi-threaded implementation.

etc.
\section{Discussion and future work}

\begin{comment}
{
\section{Deliverables}
\subsection{Usability}
\begin{description}
\item [Automate parameter scaling] base this on empirical statistics
  ``learning'' on a per registration problem basis.
\item [GetParameterSuggestion] metric and trasformation classes should
  recommend parameters from a developer-defined set.
\item [Multi-core implementations] multi threading of metric,
  regularization, parameter update, etc.  stephen indicates that the
  setparameters function may cause problems.   
\item [Unify the dense and sparse frameworks] metrics and
  transformations should be reusable across frameworks. 
\end{description}

\subsection{Data Types}
Transform vectors, curves and tensors with reorientation.

\subsection{Metrics}
\begin{description}
\item [metrics]  derivatives should be bi-directional.
\item [MI and NMI]  Shreyas --- MI and NMI multicore. 
\item [ATG Neighborhood Cross Correlation] our approximation to the
  NCC derivative.  
\item [PSE Metric] with arbitrary data type.  ObjectMetric ...
\item [Tractography/vector flow metric]  vector based.  distance transform?
\item [Multivariate metric] plug in metrics and weights and a
  ``combination'' strategy.  e.g. match 1-norm, 2-norm, etc before weighting. 
\end{description}

\subsection{Transformations}
\begin{description}
\item [BSpline]  Nick DMFFD and refactoring , bug fixing.  Usability
  and speed. 
\item [Composite transformation] need to get the composite derivatives
  right. 
\item [Deformation and rotation transform] have jeff implement.
  smooth rotation component internally (after update parameters).
\item [Velocity field] with fourth order integration.
\item [Reorientation transformation and derivative]  tensor and vector. 
\item [Rigid and deformable]  takes a mask that defines which parts
  are deformable and which are rigid.  the rigid parts are fixed by
  pre-computation.  the deformable parts are modified according to a
  registration strategy.  
\end{description}

\subsection{Regularization}
For instance, we should be able to compute a ``demons'' registration
without passing deformations to the filter.  We should pass
transformations (e.g. affine) and regularization (e.g. distance from
identity) in addition to the demons metric.  

\subsection{Longitudinal and serial registration}
Facilitate through transformations and regularization and unbiased design.
\begin{description}
\item [longitudinal] multiple images of the same subject over a longer time-scale.
\item [serial or time series] multiple images of the same subject or
  scene with high frequency sampling (samples that are dense in time).
\item [Longitudinal Image] Given a set of 3D images sampled
  longitudinally (see above), we package these $n$ images---along with
  $n$ rigid or affine transforms that map them to a common
  domain---into a standard itk image 
  interface.
\item [Serial image] this concept may already be supported.
\end{description}

\subsection{Algorithms}
\begin{description}
\item [SyN]  fully unbiased and lives as an algorithm (not
  multi-resolution) within ITK.   Multi-resolution SyN is a 2nd
  algorithm.  
\item [DMFFD] nick's style---greg's?
\item [Longitudinal Diffeomorphic Mapping] gang's version.
\item [vector versions of above]  ... with reorientation in
  transform.  also in optimization?
\end{description}


\section{The new framework}
Changes that we need to implement ASAP. 
\subsection{optimizers with regularization} We use the following
idea: any gradient based optimizer can be altered to perform the
following update scheme $ T_{i+1}=R(T_i + \lambda F(g))$ where $g$ is the
gradient and $\lambda$ is the update step.  The function $F$ is the
regularization on the gradient which will be dealt with by regularized
metrics.  So, this object should take a transform, an update to a 
transform and return the regularized transform $T_{i+1}$.  This requires a class of
optimizers that takes a regularization function as input \verb ->SetRegularizationFunction.  We will start with the gradient descent
optimizer.  Build a derived class that has a regularization function
and that overrides the update step to use that function.  It can be an
identity function for now.
\subsection{transform changes} The transforms should add a {\em thread-safe} function
called IncrementalUpdateToTransformParameters that takes a delta to
the parameters and updates the transform.  There will be an
implementation in the base class that just adds the parameters.  But
special transforms may want to override this function.  We also want a
function LocalJacobian which will default to the Jacobian computation
except in the cases where we override the function for the local,
dense transform types.
\subsection{deformation field transform} We need to resolve the
issues with the dense transform parameters.  I.e. map them
to an image efficiently or define a new local parameter type that is
based on the itkVector image.
\subsection{multivariate metric} Takes two ObjectToObjectMetrics as
input along with a weight function.  Defaults to uniform weighting
unless otherwise specified.  Weights are applied to the gradients of
the metric, not the metric itself.  
\subsection{multi-threading}  We need to be careful in making
decisions about all the above.  For instance, what is needed to make
the transforms thread-safe?   The regularizers?
\subsection{lightweight resampling}  Can we implement a lightweight
resample function that is local, thread-safe and samples an image in
such a way that code becomes more readable?  I.e. does the bounds
checking, reorientation, etc.  Relatedly, can the resample image
filter be rewritten with code reuse as an objective?
\subsection{multi-threaded metrics}  Gang wrote an initial
implementation.  We need to continue to work on this --- the demons
version needs to take a generic iterator type or allow different
iterators to be selected by the user.  

\subsection{the first new registration object}

SetImages 

SetRegistrationMachineryObjects --- what type of object is the
registration machinery?  really just a holder with reasonable defaults
for the stuff that needs to be set up.  Relies on get recommended
parameters and baohua's scale parameter setter to set up the defaults
for optimizer, metric etc.

SetOptimizer --- that will be in the machine but the optimizer might
have a regularization function which will have parameters.
Alternatively, we define regularized metrics that takes an
unregularized metric as input along with a regularizer and just
returns the regularized gradient---maybe a better idea!  A regularized
metric will project the gradient to the space in which it should
live.  

SetResolutions --- virtual domains along with scales?  kind of unclear 

SetVirtualDomain --- related to above 

RunRegistration --- given above, runs the registration.  Need a
convergence criterion.  

\section{Frobenius norm registration}
A three-dimensional problem with a derivative on $\x$, the spatial domain.
Let us assume that $\I \colon \Omega \in [0,1]^d \rightarrow
\mathbb{R}^d$ where $d$ defines the dimensionality. 
Homogeneous coordinates make this easier.
\begin{eqnarray}
T(\x) =\y = [A(\theta)] \phi(\x)= [A(\theta)] (\x+U(\x)) \\ \notag 
\J(T) = \R^T\J(\y)\R  \\ \notag 
\R =\text{R part of polar decomposition of }   \\ \notag
   [A(\theta)] (\Id+U_\x(\x))   \\ \notag
 \text{must compose affine with deformation gradient} \\ \notag
\text{in order that correctly reorients the data.}  \\ \notag
\| \I - \J (T) \|^2  \\ \notag 
\frac{\partial}{\partial \x} \| \I - \J (T) \|^2 \\ \notag
< \I - \J (T) , \frac{\partial}{\partial \x} (  \I - \J (T)  ) >  \\ \notag
\frac{\partial}{\partial \x} (  \I - \J (T)  ) =  \\ \notag
\frac{\partial}{\partial \x} \J (T)  =  \\ \notag
\text{ chain rule gets ugly ...}
\end{eqnarray}
}
\end{comment}
% \bibliographystyle{IEEEbib}
% \bibliography{./none}
\end{document}
